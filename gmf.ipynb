{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "586a76ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# -----------------------------\n",
    "# Device\n",
    "# -----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ca7ef8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"data/ratings.csv\").drop(columns=[\"timestamp\"])\n",
    "ratings[\"label\"] = (ratings[\"rating\"] >= 4.0).astype(int)\n",
    "\n",
    "uids = ratings[\"userId\"].unique()\n",
    "iids = ratings[\"movieId\"].unique()\n",
    "uid2idx = {u:i for i,u in enumerate(uids)}\n",
    "iid2idx = {m:i for i,m in enumerate(iids)}\n",
    "ratings[\"userId\"] = ratings[\"userId\"].map(uid2idx)\n",
    "ratings[\"movieId\"] = ratings[\"movieId\"].map(iid2idx)\n",
    "\n",
    "n_users = ratings[\"userId\"].nunique()\n",
    "n_items = ratings[\"movieId\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1c268622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  label\n",
       "0       0        0     4.0      1\n",
       "1       0        1     4.0      1\n",
       "2       0        2     4.0      1\n",
       "3       0        3     5.0      1\n",
       "4       0        4     5.0      1"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "033ef52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 100227, Test size: 609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tk/fdx_zq9j7ys9h_dvcc825byc0000gn/T/ipykernel_78118/1610604659.py:3: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  test_idx = pos.groupby(\"userId\", group_keys=False).apply(lambda x: x.sample(1, random_state=42)).index\n"
     ]
    }
   ],
   "source": [
    "# one positive per user in test\n",
    "pos = ratings[ratings.label == 1]\n",
    "test_idx = pos.groupby(\"userId\", group_keys=False).apply(lambda x: x.sample(1, random_state=42)).index\n",
    "test_df = ratings.loc[test_idx][[\"userId\",\"movieId\",\"label\"]]\n",
    "train_df = ratings.drop(test_idx)\n",
    "\n",
    "train_ui = set(zip(train_df.userId.tolist(), train_df.movieId.tolist()))\n",
    "\n",
    "print(f\"Train size: {len(train_df)}, Test size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "1efa65ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 2) GMF model (implicit)\n",
    "# -----------------------------\n",
    "class GMF_Implicit(nn.Module):\n",
    "    def __init__(self, n_users, n_items, k=32):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, k)\n",
    "        self.item_emb = nn.Embedding(n_items, k)\n",
    "        nn.init.normal_(self.user_emb.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_emb.weight, std=0.01)\n",
    "\n",
    "        # linear layer on top of elementwise product\n",
    "        self.fc = nn.Linear(k, 1)\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        nn.init.zeros_(self.fc.bias)\n",
    "\n",
    "    def forward(self, u, i):\n",
    "        z = self.user_emb(u) * self.item_emb(i)  # elementwise product\n",
    "        return self.fc(z).view(-1)  # logits (before sigmoid)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5be07ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Negative sampling (same as MF)\n",
    "# -----------------------------\n",
    "def sample_train_batch(train_df, n_items, train_ui, num_neg=4, users_subset=None):\n",
    "    if users_subset is None:\n",
    "        users = train_df[train_df.label==1][\"userId\"].unique().tolist()\n",
    "    else:\n",
    "        users = users_subset\n",
    "    U,I,Y = [],[],[]\n",
    "    for u in users:\n",
    "        pos_items = train_df[(train_df.userId==u) & (train_df.label==1)].movieId.tolist()\n",
    "        if not pos_items: continue\n",
    "        ip = random.choice(pos_items)\n",
    "        U.append(u); I.append(ip); Y.append(1.0)\n",
    "        negs=0\n",
    "        while negs<num_neg:\n",
    "            j = random.randint(0, n_items-1)\n",
    "            if (u,j) not in train_ui and j!=ip:\n",
    "                U.append(u); I.append(j); Y.append(0.0)\n",
    "                negs+=1\n",
    "    return torch.LongTensor(U), torch.LongTensor(I), torch.FloatTensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "471e7506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 4) Evaluation (HR@K, NDCG@K)\n",
    "# -----------------------------\n",
    "def eval_hr_ndcg(model, test_df, train_ui, n_items, k=10, n_neg=100, device=\"cpu\"):\n",
    "    model.eval(); HR=0.0; N=0.0; cnt=0\n",
    "    rng = np.random.default_rng(123)\n",
    "    with torch.no_grad():\n",
    "        for _, row in test_df.iterrows():\n",
    "            u, ip = int(row.userId), int(row.movieId)\n",
    "            seen = {i for (uu,i) in train_ui if uu==u}\n",
    "            negs = []\n",
    "            while len(negs)<n_neg:\n",
    "                j = int(rng.integers(0,n_items))\n",
    "                if j!=ip and j not in seen: negs.append(j)\n",
    "            cands = [ip]+negs\n",
    "            U = torch.LongTensor([u]*(1+n_neg)).to(device)\n",
    "            I = torch.LongTensor(cands).to(device)\n",
    "            scores = model(U,I).cpu().numpy()\n",
    "            topk_idx = scores.argsort()[-k:][::-1]\n",
    "            topk = [cands[t] for t in topk_idx]\n",
    "            hit = 1.0 if ip in topk else 0.0; HR+=hit\n",
    "            if hit:\n",
    "                rank = topk.index(ip)+1\n",
    "                N+=1.0/math.log2(rank+1)\n",
    "            cnt+=1\n",
    "    return HR/cnt, N/cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e6050520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Loss: 0.6931 | HR@10: 0.0936 | NDCG@10: 0.0462\n",
      "Epoch 02 | Loss: 0.6929 | HR@10: 0.0969 | NDCG@10: 0.0478\n",
      "Epoch 04 | Loss: 0.6924 | HR@10: 0.1002 | NDCG@10: 0.0490\n",
      "Epoch 06 | Loss: 0.6919 | HR@10: 0.1034 | NDCG@10: 0.0497\n",
      "Epoch 08 | Loss: 0.6915 | HR@10: 0.1051 | NDCG@10: 0.0521\n",
      "Epoch 10 | Loss: 0.6910 | HR@10: 0.1051 | NDCG@10: 0.0520\n",
      "Epoch 12 | Loss: 0.6905 | HR@10: 0.1100 | NDCG@10: 0.0531\n",
      "Epoch 14 | Loss: 0.6900 | HR@10: 0.1166 | NDCG@10: 0.0556\n",
      "Epoch 16 | Loss: 0.6896 | HR@10: 0.1166 | NDCG@10: 0.0561\n",
      "Epoch 18 | Loss: 0.6891 | HR@10: 0.1232 | NDCG@10: 0.0595\n",
      "Epoch 20 | Loss: 0.6886 | HR@10: 0.1314 | NDCG@10: 0.0626\n",
      "Epoch 22 | Loss: 0.6881 | HR@10: 0.1314 | NDCG@10: 0.0631\n",
      "Epoch 24 | Loss: 0.6877 | HR@10: 0.1379 | NDCG@10: 0.0682\n",
      "Epoch 26 | Loss: 0.6872 | HR@10: 0.1544 | NDCG@10: 0.0743\n",
      "Epoch 28 | Loss: 0.6867 | HR@10: 0.1511 | NDCG@10: 0.0779\n",
      "Epoch 30 | Loss: 0.6863 | HR@10: 0.1511 | NDCG@10: 0.0803\n",
      "Epoch 32 | Loss: 0.6858 | HR@10: 0.1626 | NDCG@10: 0.0854\n",
      "Epoch 34 | Loss: 0.6853 | HR@10: 0.1724 | NDCG@10: 0.0924\n",
      "Epoch 36 | Loss: 0.6848 | HR@10: 0.1839 | NDCG@10: 0.1010\n",
      "Epoch 38 | Loss: 0.6844 | HR@10: 0.1921 | NDCG@10: 0.1064\n",
      "Epoch 40 | Loss: 0.6839 | HR@10: 0.2053 | NDCG@10: 0.1173\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 5) Train GMF implicit\n",
    "# -----------------------------\n",
    "model = GMF_Implicit(n_users, n_items, k=32).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=8e-4, weight_decay=1e-6)\n",
    "\n",
    "epochs = 40\n",
    "for e in range(1, epochs+1):\n",
    "    model.train()\n",
    "    U,I,Y = sample_train_batch(train_df, n_items, train_ui, num_neg=4)\n",
    "    U,I,Y = U.to(device), I.to(device), Y.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(model(U,I), Y); loss.backward(); optimizer.step()\n",
    "\n",
    "    if e==1 or e%2==0:\n",
    "        hr, ndcg = eval_hr_ndcg(model, test_df, train_ui, n_items, k=10, n_neg=100, device=device)\n",
    "        print(f\"Epoch {e:02d} | Loss: {loss.item():.4f} | HR@10: {hr:.4f} | NDCG@10: {ndcg:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
